{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAUA6cvb_CNY"
      },
      "source": [
        "# 5TF078 Deep Learning Course\n",
        "## Excercise 1 Convolutional Neural Networks on Fashion-MNIST\n",
        "Created by Tomas Nordström, Umeå University\n",
        "\n",
        "Revisions:\n",
        "* 2022-03-23 First revision based on earlier excercises /ToNo\n",
        "* 2022-03-30 Adjusted the Keras Tuner search to reduce compute times. /Tomas\n",
        "* 2022-04-05 Added padding='same' as an argument to Conv2D. /Tomas\n",
        "* 2022-05-09 Swaped optimizer to use 'adam' as default and 'sgd' as extra test. /Tomas\n",
        "* 2022-05-09 Fixed so that we can use the latest version (1.1.2) of keras tuner. /Tomas\n",
        "* 2022-11-07 Added hints to use incremental model definitions when we want to have varying number of layers with Keras tuner. /Tomas\n",
        "* 2022-11-09 Updated check for colab to NOT use env. var. COLAB_GPU as it has gone missing. /Tomas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAWshxTD0Sd8"
      },
      "source": [
        "## **Glöm inte ditt namn!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-tp9iDDCpsz"
      },
      "source": [
        "# First we initilize our Python environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1pcr2Em_Lzo",
        "outputId": "ffa669f6-b5ca-4851-8810-48a8b79cb2c5",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.8.0\n",
            "Keras version: 2.8.0\n"
          ]
        }
      ],
      "source": [
        "# Import needed libraries\n",
        "import tensorflow as tf\n",
        "print('TensorFlow version:', tf.__version__)\n",
        "\n",
        "from tensorflow import keras\n",
        "# from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, BatchNormalization, Dropout, \\\n",
        "                         MaxPooling2D, Input, Activation, Add\n",
        "from keras.utils  import to_categorical\n",
        "from keras.models import Model, Sequential\n",
        "print('Keras version:',tf.keras.__version__)\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from   sklearn.model_selection import train_test_split\n",
        "\n",
        "# Matlab plotting\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Typing imports for type hints / readability\n",
        "from typing import Tuple, List, Dict, Any, Union\n",
        "init = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf0ZWo9JyEhS",
        "outputId": "5e0ca4c6-4946-4c86-b948-e4d8d9f62eb7",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: NVIDIA GeForce RTX 3090 (UUID: GPU-56d64c0c-e161-9720-5e6d-9848f27424d1)\r\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-09 17:39:26.472589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-09 17:39:26.492555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-09 17:39:26.492656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
          ]
        }
      ],
      "source": [
        "# Test for GPU and determine what GPU we have\n",
        "import sys\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "     print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
        "     IN_COLAB = 'google.colab' in sys.modules\n",
        "     if IN_COLAB:\n",
        "         print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "else:\n",
        "     !nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhWTXQfXBiN6"
      },
      "source": [
        "# Set up the needed data sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmtboE3kolMi"
      },
      "source": [
        "## Get hold of a data-set\n",
        "In this exercise we will use Fashion MNIST dataset, which an alternative to MNIST (it is a little harder, but the image size is the same). This is available directly as a [Keras dataset](https://keras.io/datasets/). This is a dataset of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images. \n",
        "\n",
        "Note that we split our data into **three** data sets: training, validation, testing; each with its own purpose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ViGcOSI-_t6",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Get Fashion-MNIST training and test data from Keras database (https://keras.io/datasets/)\n",
        "(train_images0, train_labels0), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Define labels\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "# Split the training set into a training and a validation set (20% is validation)\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(train_images0, train_labels0, test_size=0.20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNZOs2YwraHQ",
        "outputId": "26499e66-ce57-4e0b-fe1e-e4efae43c0fe",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No training images: 48000  with image size: 28 x 28\n",
            "No test images: 10000\n",
            "No val images: 12000\n",
            "Training labels: [0 1 2 3 4 5 6 7 8 9] ; That is, 10 classes.\n"
          ]
        }
      ],
      "source": [
        "# Print som basic information of data set sizes and data sizes\n",
        "train_no,x,y = train_images.shape\n",
        "print('No training images:',train_no, ' with image size:',x,'x',y)\n",
        "label_no = len(train_labels)\n",
        "if (label_no != train_no) : \n",
        "  print('# labels do not match # training images')\n",
        "\n",
        "test_no,x,y = test_images.shape\n",
        "label_no = len(test_labels)\n",
        "print('No test images:',test_no)\n",
        "if (label_no != test_no) : \n",
        "  print('# labels do not match # test images')\n",
        "\n",
        "val_no,x,y = val_images.shape\n",
        "label_no = len(val_labels)\n",
        "print('No val images:',val_no)\n",
        "if (label_no != val_no) : \n",
        "  print('# labels do not match # val images')\n",
        "\n",
        "classes = np.unique(train_labels)\n",
        "num_classes = len(classes)\n",
        "print('Training labels:', np.unique(train_labels), \"; That is,\", num_classes,\"classes.\" )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cg4WF2gMzfpm"
      },
      "source": [
        "Note that the training labels are an integer between 0 and 9, which is not very good as outputs (or inputs) for DL models. A better approach would be to use a one-hot encoding. We can convert our label vectors to one-hot encoded matrices by using [to_categorical](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) `tf.keras.utils.to_categorical(train_labels)`.\n",
        "\n",
        "But we can achieve the same thing by using [SparseCategoricalCrossentropy](https://keras.io/api/losses/probabilistic_losses/#sparsecategoricalcrossentropy-class) as a loss function instead of the [CategoricalCrossentropy](https://keras.io/api/losses/probabilistic_losses/#categoricalcrossentropy-class). Also note that in both cases we need our model to have as many output nodes as we have classes! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYVB7wI8sFgh"
      },
      "source": [
        "## Adjust the data to be better work as ML input\n",
        "\n",
        "Many models working with images are assuming the data to be represented as a 4-D tensor with the shape BHWC [batch_size, height, width, channels] (some ML frameworks prefer to use BCHW instead, so be careful when starting to work on new datasets or ML-frameworks).\n",
        "\n",
        "We also want to normalize data to be \"small\" and \"close\" to zero, e.g. 0 to 1 or –1 to 1. In this example we normalize to values between –0.5 and 0.5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XL5_y51yqOkR",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Add an \"empty\" color dimension for our data sets\n",
        "def pre_process():\n",
        "    train_images = np.expand_dims(train_images, -1)\n",
        "    val_images = np.expand_dims(val_images, -1)\n",
        "    test_images = np.expand_dims(test_images, -1)\n",
        "\n",
        "    # Normalize the images.\n",
        "    train_images = (train_images / 255) - 0.5\n",
        "    test_images = (test_images / 255) - 0.5\n",
        "    val_images = (val_images / 255) - 0.5\n",
        "if init:\n",
        "    pre_process()\n",
        "    init = not init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9F4zkQQDnAz"
      },
      "source": [
        "## Explore the data\n",
        "It is always advised to take a look at the data, to see if we need to massage it further."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "dMYGkeRxJ__U",
        "outputId": "91b6f04a-37e4-4830-ac3b-d3564ebc76d0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: Pullover\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: Sandal\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAR50lEQVR4nO3dbWyVZZoH8P/fUgHLixUFwdYXBtAlW5dBUNRxZRycsGjUMc5kSFzdiNtRx2QmjAkGPwx+IJpVxmz8MEnHF5jNLJMJDBETs+NLJDoxTqDSRQRRFovQ1gKR98pbe+2HPk6q9rnu43nOc86B+/9Lmrbn6v2cm6P/PqfnOvdz08wgIme+syo9AREpD4VdJBIKu0gkFHaRSCjsIpEYUs47I6mX/kVyZmYc7PZMZ3aSc0luI7md5KNZjiUi+WKxfXaSNQA+AnAzgN0A1gOYb2ZbnDE6s4vkLI8z+9UAtpvZDjM7AeCPAG7PcDwRyVGWsF8EYNeA73cnt30FyWaSG0huyHBfIpJRlhfoBnuq8I2n6WbWAqAF0NN4kUrKcmbfDaBxwPcNADqzTUdE8pIl7OsBTCZ5GcmzAfwUwNrSTEtESq3op/FmdorkwwD+AqAGwAtm9kHJZnYaOess/3dmX19fpvGXXnqpW58wYUJq7cILL3THjh492q3v2LHDrV9xxRVufe7cuUUfu76+3q0PHTrUrdfV1aXWent73bEhjz/+uFtva2vLdPw8ZHpTjZm9AuCVEs1FRHKkt8uKREJhF4mEwi4SCYVdJBIKu0gkFHaRSBS96q2oOztD3y5bW1vr1k+ePOnWn3jiCbd+5513uvVt27al1k6cOOGODfXZR40a5dZ37drl1r1eeFNTkzv21KlTbn39+vVufe/evam1DRv8pRqLFi1y693d3W79pptucut5ymU9u4icPhR2kUgo7CKRUNhFIqGwi0RCYReJhFpvJTBkiL94MNRCmjVrllu/66673HpPT49b93R0dLj10DLSUAvrnXfe+dZzqgarVq1y6wcPHnTrW7akXncVALBs2bJvPadCqfUmEjmFXSQSCrtIJBR2kUgo7CKRUNhFIqGwi0RCfXY5bWVdWuwJ5SJ0+e+dO3e69dtuuy21FroMdU1NTWqtt7dXfXaR2CnsIpFQ2EUiobCLREJhF4mEwi4SCYVdJBLqs1cBr28KhHu+WcZm7SdnkXVu5KDt5ILGhy6hfeDAgUz3vW7dOrfe0NCQWps0aZI7NiStz55py2aS7QAOA+gFcMrMZmQ5nojkJ1PYE983s30lOI6I5Eh/s4tEImvYDcCrJFtJNg/2AySbSW4g6V+sTERylfVp/PVm1klyLIDXSH5oZm8N/AEzawHQAugFOpFKynRmN7PO5PMeAGsAXF2KSYlI6RUddpJ1JEd++TWAHwLYXKqJiUhpZXkaPw7AmqTfOATAf5vZ/5RkVmeYUE+2r6/PrWfpN2d9H0VoblmEHpeQ0PsTvOv1T58+PdN9h7z77rtu/ZZbbkmtzZ8/3x27cuXKouZUdNjNbAeAfyp2vIiUl1pvIpFQ2EUiobCLREJhF4mEwi4SiVIshJGArEs1sx6/WmWdd5bxTU1Nme475NixY2790KFDqbX77rvPHfvmm2+m1vbtS1+TpjO7SCQUdpFIKOwikVDYRSKhsItEQmEXiYTCLhIJ9dmrQNY+fJYlrqdrjz6rMWPGuPWenp5Mxz9+/Lhb7+3tTa3V1dW5Y73LUHv9e53ZRSKhsItEQmEXiYTCLhIJhV0kEgq7SCQUdpFIqM9+GsjSK6+trXXHZr2MdYg3PuuxvV51yNSpU9369u3biz42AEyYMMGte730I0eOuGMvuOCC1NqQIemR1pldJBIKu0gkFHaRSCjsIpFQ2EUiobCLREJhF4mE+uxngLPOSv+dffLkyTLOpLSGDh3q1kNrxj3emnAA2LRpU9HHBvztogH/v5lXA/xr0nvvXQie2Um+QHIPyc0DbjuP5GskP04+14eOIyKVVcjT+OUA5n7ttkcBvGFmkwG8kXwvIlUsGHYzewvA51+7+XYAK5KvVwC4o7TTEpFSK/Zv9nFm1gUAZtZFcmzaD5JsBtBc5P2ISInk/gKdmbUAaAEAknFe3VCkChTbeusmOR4Aks97SjclEclDsWFfC+De5Ot7AbxUmumISF6CT+NJrgQwG8D5JHcD+DWAJwH8ieQCAJ8C+HGekzzd1dTUuPXQuuzQNc6XLVuWWhs3bpw7duPGjW599erVbr21tdWtZ5Gljw74j1vocXnxxRcz3fekSZPc+okTJ1Jrob3d33777dSa198Pht3M5qeUfhAaKyLVQ2+XFYmEwi4SCYVdJBIKu0gkFHaRSLCcW/bqHXT5GDZsWGrtwQcfdMfOmzfPrU+cONGtDx8+3K1/+umnqbW2tjZ37LZt29z6qlWr3Prhw4dTa2vWrHHHfvLJJ27du5wzEL6U9NGjR1NrXlsOAObMmePWzWzQPbx1ZheJhMIuEgmFXSQSCrtIJBR2kUgo7CKRUNhFIqE++2lg/Pjxbr2rq6voY5ODtmT/bvLkyW599uzZbr2pqSm1Nm3aNHdsqD5ixAi3PnLkyNTa2rVr3bGhJbChZcmfffaZWx81alRq7eWXX3bHLl261K2rzy4SOYVdJBIKu0gkFHaRSCjsIpFQ2EUiobCLREJbNleB0aNHu/XQFr51dXWptcsuu8wd29jY6NZD67a3bNni1r2ecej9AaE14VOmTHHrd999d2pt5syZ7thbb73VrX/xxRdu/amnnnLr3n/Tl17KZxsGndlFIqGwi0RCYReJhMIuEgmFXSQSCrtIJBR2kUioz14FQtcJ7+jocOve2uuenh53bG1trVv3evgA0NDQ4Navvfba1FpoTXnouvGdnZ1u3btu/LnnnuuODa1XD9m5c6db97Z03rx5c6b7ThM8s5N8geQekpsH3LaEZAfJtuTD32lARCqukKfxywHMHeT2Z8xsWvLxSmmnJSKlFgy7mb0F4PMyzEVEcpTlBbqHSW5KnubXp/0QyWaSG0huyHBfIpJRsWH/LYDvAJgGoAvAsrQfNLMWM5thZjOKvC8RKYGiwm5m3WbWa2Z9AH4H4OrSTktESq2osJMceG3jHwHIp1cgIiUT7LOTXAlgNoDzSe4G8GsAs0lOA2AA2gH8LL8pnv6GDPEf5uuuu86th3q27e3tqTWv1wwA11xzjVv/6KOP3Pq+ffvcurfevbu72x0b8sgjj7h1b4/11tbWTPcdcvDgQbe+d+/eXO9/MMGwm9n8QW5+Poe5iEiO9HZZkUgo7CKRUNhFIqGwi0RCYReJhJa4JkLtMe/Sv319fe7YU6dOufVQG+iGG25w69OnT0+t1dTUuGNDWzKHWkShemgZqueee+5x68eOHXPrq1evTq2FHpesS1xDl5res2dPpuMXQ2d2kUgo7CKRUNhFIqGwi0RCYReJhMIuEgmFXSQS6rMnQr3wPB04cMCte9seh3iXLAbCl7EObW0c6nUfP348tXbzzTe7Y8eOHevWn376abfuvTci1Ecn6dbNzK2Hjh9aepwHndlFIqGwi0RCYReJhMIuEgmFXSQSCrtIJBR2kUioz54YNmyYW3/ggQdSa6G10cuWpW6Yk7vt27dnqodccsklbn3jxo2ptXXr1rljQ+vZQ73wvMaW4vih9e550JldJBIKu0gkFHaRSCjsIpFQ2EUiobCLREJhF4lE2fvsXv8xdO127/rsob5maL36kiVL3PrUqVNTa6G1yUOHDnXr3prvQnjrtkPrrkP1kIULF7r1o0ePptYWLFiQ6b7z/Ldl7cOfffbZbv3IkSNFH9ubm/dvDp7ZSTaSfJPkVpIfkPxFcvt5JF8j+XHyub6YiYtIeRTyNP4UgF+Z2T8AmAXg5ySnAngUwBtmNhnAG8n3IlKlgmE3sy4zey/5+jCArQAuAnA7gBXJj60AcEdOcxSREvhWf7OTvBTAdwH8DcA4M+sC+n8hkBz0gmEkmwE0Z5yniGRUcNhJjgCwGsAvzexQoS9gmFkLgJbkGNleDRKRohXUeiNZi/6g/8HM/pzc3E1yfFIfD6D821KKSMGCZ3b2n8KfB7DVzH4zoLQWwL0Ankw+v1TIHXqtgZMnTxZyiFwsX77crS9dujS1NnLkSHdsc7P/V8yzzz7r1kNCW0ZnMXHiRLc+Z84ct/7qq6+m1rL+9856uee8xgJAbW2tW8+6JXQxCnkafz2AfwXwPsm25LbF6A/5n0guAPApgB/nMkMRKYlg2M3srwDSfoX+oLTTEZG86O2yIpFQ2EUiobCLREJhF4mEwi4Siaq6lPSYMWPc+uWXX55aa2xsdMd6y0ABYNasWW69vj59Ud/+/fvdsaFLIj/33HNuPdRP9pbQhpbfhpb+Ll682K2HLqP9zDPPuPUssvbC8zR8+HC3XoktwnVmF4mEwi4SCYVdJBIKu0gkFHaRSCjsIpFQ2EUiUdY+e319vbv++f7773fHez3jUC86tL44tCbd22I3dNngUE/1oYcecuuhLZ+PHTuWWgv1wR977DG3fuONN7r1119/3a23t7e79TNVnuvZc7uUtIicGRR2kUgo7CKRUNhFIqGwi0RCYReJhMIuEomy9tn379+PNWvWpNanTJnijr/yyitTa+ecc447NrQddGjd97Bhw1JroR59qM8+e/Zstx76t3n339DQ4I5tampy652dnW590aJFbj1Wea5nL3Ydv87sIpFQ2EUiobCLREJhF4mEwi4SCYVdJBIKu0gkCtmfvRHA7wFcCKAPQIuZ/SfJJQD+HcDe5EcXm9kroeN5/UVvD/SQSZMmufWZM2dmql988cWptREjRrhjQ2uXQ73wadOmuXVvPfuuXbvcsa2trW594cKFbv3QoUNu/XQVem9DT0+PW6+rqyvldL6i2PXshbyp5hSAX5nZeyRHAmgl+VpSe8bMnv42ExWRyihkf/YuAF3J14dJbgVwUd4TE5HS+lZ/s5O8FMB3AfwtuelhkptIvkBy0P2RSDaT3EByQ7apikgWBYed5AgAqwH80swOAfgtgO8AmIb+M/+gF0ozsxYzm2FmM7JPV0SKVVDYSdaiP+h/MLM/A4CZdZtZr5n1AfgdgKvzm6aIZBUMO/tf+nsewFYz+82A28cP+LEfAdhc+umJSKkwtFyO5PcAvA3gffS33gBgMYD56H8KbwDaAfwseTHPO1b17rGbo9Byx6uuuirT8fft25da+/DDDzMdO1ahS3CH2qneJdMBYOvWram1jo4Od2yImQ3amyvk1fi/AhhscLCnLiLVQ++gE4mEwi4SCYVdJBIKu0gkFHaRSCjsIpEI9tlLemeR9tlFyimtz64zu0gkFHaRSCjsIpFQ2EUiobCLREJhF4mEwi4SibJu2QxgH4CdA74/P7mtGlXr3Kp1XoDmVqxSzu2StEJZ31TzjTsnN1TrtemqdW7VOi9AcytWueamp/EikVDYRSJR6bC3VPj+PdU6t2qdF6C5Fassc6vo3+wiUj6VPrOLSJko7CKRqEjYSc4luY3kdpKPVmIOaUi2k3yfZFul96dL9tDbQ3LzgNvOI/kayY+Tz4PusVehuS0h2ZE8dm0k51Vobo0k3yS5leQHJH+R3F7Rx86ZV1ket7L/zU6yBsBHAG4GsBvAegDzzWxLWSeSgmQ7gBlmVvE3YJD8ZwBHAPzezP4xue0/AHxuZk8mvyjrzWxRlcxtCYAjld7GO9mtaPzAbcYB3AHg31DBx86Z109QhsetEmf2qwFsN7MdZnYCwB8B3F6BeVQ9M3sLwOdfu/l2ACuSr1eg/3+WskuZW1Uwsy4zey/5+jCAL7cZr+hj58yrLCoR9osA7Brw/W5U137vBuBVkq0kmys9mUGM+3KbreTz2ArP5+uC23iX09e2Ga+ax66Y7c+zqkTYB7s+VjX1/643s+kA/gXAz5Onq1KYgrbxLpdBthmvCsVuf55VJcK+G0DjgO8bAHRWYB6DMrPO5PMeAGtQfVtRd3+5g27yeU+F5/N31bSN92DbjKMKHrtKbn9eibCvBzCZ5GUkzwbwUwBrKzCPbyBZl7xwApJ1AH6I6tuKei2Ae5Ov7wXwUgXn8hXVso132jbjqPBjV/Htz82s7B8A5qH/Ffn/A/BYJeaQMq+JAP43+fig0nMDsBL9T+tOov8Z0QIAYwC8AeDj5PN5VTS3/0L/1t6b0B+s8RWa2/fQ/6fhJgBtyce8Sj92zrzK8rjp7bIikdA76EQiobCLREJhF4mEwi4SCYVdJBIKu0gkFHaRSPw/4YDoquHSTUEAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# As these are images (28x28) it can be interesting to plot some as images\n",
        "\n",
        "image_index = [42, 789] # \"Random\" images to print\n",
        "str2data = {\n",
        "  \"train\": (train_images, train_labels),\n",
        "  \"val\": (val_images, val_labels),\n",
        "  \"test\": (test_images, test_labels)\n",
        "}\n",
        "def plot_sample(index:List[int], data:str=\"train\"):\n",
        "  images, labels = str2data[data]\n",
        "  for index in image_index:\n",
        "    print( 'Label:', class_names[train_labels[index]])\n",
        "    plt.figure()\n",
        "    plt.imshow(np.squeeze(train_images[index], axis=-1))\n",
        "    plt.gray()\n",
        "    plt.grid(False)\n",
        "    plt.show(block=False)\n",
        "plot_sample(image_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7CFf7AO4ysm"
      },
      "source": [
        "# Define a convolutional network model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "948BTPYO5BI_"
      },
      "source": [
        "## Define the model using Keras\n",
        "\n",
        "Note that this is a *very* small modell just to have a strating point. A good modell is expected to have 5-50 times as many parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHl97r_t4_2t",
        "outputId": "de4c3297-8777-42c0-b8cf-b53d15227fef",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape (28, 28, 1)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 16)        160       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12544)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                200720    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                170       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 201,050\n",
            "Trainable params: 201,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-09 17:39:27.112908: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-05-09 17:39:27.114264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-09 17:39:27.114455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-09 17:39:27.114551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-09 17:39:27.408608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-09 17:39:27.408751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-09 17:39:27.408841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-05-09 17:39:27.408896: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-05-09 17:39:27.408922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22186 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "# We need to give the input shape (i.e. our image shape) to our model\n",
        "input_shape = test_images[0].shape\n",
        "print(\"Input shape\", input_shape)\n",
        "\n",
        "# The Keras model will be the simplest Keras model for NN networks. \n",
        "# It is a single stack of layers connected sequentially.\n",
        "def simple_model()->Sequential:\n",
        "    model = Sequential([\n",
        "\n",
        "    # Add a convolution layer\n",
        "    Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
        "\n",
        "    # Flatten the input. This prepares the vector for fully connected layers.\n",
        "    Flatten(),\n",
        "\n",
        "    # Add a hidden Dense layer\n",
        "    Dense(units=16, activation='relu'),\n",
        "\n",
        "    # Add a an output layer. The output space is the number of classes\n",
        "    #    Softmax makes the output as probablity vector of the different classes\n",
        "    Dense(units=num_classes, activation='softmax')\n",
        "\n",
        "    ])\n",
        "    print(\"Simple Model\")\n",
        "    print(model.summary())\n",
        "    return model\n",
        "def resnet_model()->Model:\n",
        "    inp = Input(shape=input_shape)\n",
        "    ## TODO: Add your ResNet model here\n",
        "    return None\n",
        "\n",
        "model = simple_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7opTLcKc73By"
      },
      "source": [
        "# Set up the model and optimizer for training\n",
        "To set up the optimization of this model we need to compile it, and set what [optimizer](https://keras.io/api/optimizers/), what [loss](https://keras.io/api/losses/), and what [metrics](https://keras.io/api/metrics/) to use. Where, metric is similar to a loss but not used during training but can be used to measure training progress.\n",
        "\n",
        "The model (its parameters) is also initialized to some random values during this phase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luIM0Q8I9I9_",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Compile the model, as a preparation for training\n",
        "def compile_model(model:Model,loss:Union[keras.losses.Loss, str],metrics:List)->Model:\n",
        "  model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=loss,\n",
        "    metrics=metrics\n",
        "  )\n",
        "  return model\n",
        "model = compile_model(model, 'categorical_crossentropy', ['categorical_accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q56fJLY89amp"
      },
      "source": [
        "# Run the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnJObQvJ-Gv7",
        "outputId": "a96e174c-94cb-4d84-a84b-c66a27253ae9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-09 17:39:28.412941: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  45/1500 [..............................] - ETA: 1s - loss: 1.4234 - categorical_accuracy: 0.5236   "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-09 17:39:29.156084: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1500/1500 [==============================] - 4s 1ms/step - loss: 0.4799 - categorical_accuracy: 0.8330 - val_loss: 0.3719 - val_categorical_accuracy: 0.8681\n",
            "Epoch 2/15\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3185 - categorical_accuracy: 0.8860 - val_loss: 0.3235 - val_categorical_accuracy: 0.8866\n",
            "Epoch 3/15\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2769 - categorical_accuracy: 0.9003 - val_loss: 0.3047 - val_categorical_accuracy: 0.8942\n",
            "Epoch 4/15\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2500 - categorical_accuracy: 0.9096 - val_loss: 0.3316 - val_categorical_accuracy: 0.8826\n",
            "Epoch 5/15\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2286 - categorical_accuracy: 0.9176 - val_loss: 0.3110 - val_categorical_accuracy: 0.8889\n",
            "Epoch 6/15\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2094 - categorical_accuracy: 0.9242 - val_loss: 0.2945 - val_categorical_accuracy: 0.8977\n",
            "Epoch 7/15\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1931 - categorical_accuracy: 0.9303 - val_loss: 0.3069 - val_categorical_accuracy: 0.8974\n",
            "Epoch 8/15\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1745 - categorical_accuracy: 0.9375 - val_loss: 0.3071 - val_categorical_accuracy: 0.8997\n",
            "Epoch 9/15\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1632 - categorical_accuracy: 0.9408 - val_loss: 0.2980 - val_categorical_accuracy: 0.8989\n",
            "Epoch 10/15\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1480 - categorical_accuracy: 0.9470 - val_loss: 0.3154 - val_categorical_accuracy: 0.9007\n",
            "Epoch 11/15\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1379 - categorical_accuracy: 0.9506 - val_loss: 0.3265 - val_categorical_accuracy: 0.9017\n",
            "Epoch 12/15\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1268 - categorical_accuracy: 0.9548 - val_loss: 0.3198 - val_categorical_accuracy: 0.9035\n",
            "Epoch 13/15\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1183 - categorical_accuracy: 0.9577 - val_loss: 0.3308 - val_categorical_accuracy: 0.9016\n",
            "Epoch 14/15\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1058 - categorical_accuracy: 0.9621 - val_loss: 0.3486 - val_categorical_accuracy: 0.9003\n",
            "Epoch 15/15\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.0978 - categorical_accuracy: 0.9656 - val_loss: 0.3786 - val_categorical_accuracy: 0.8963\n"
          ]
        }
      ],
      "source": [
        "epochs = 15      ## Number of epoch to run\n",
        "batch_size = 32  ## Mini batch size\n",
        "def train_model(model:Model, epochs:int, batch_size:int)->keras.callbacks.History:\n",
        "  # Train the model.\n",
        "  history = model.fit(\n",
        "    train_images, to_categorical(train_labels),\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    verbose = 1,\n",
        "    validation_data=(val_images, to_categorical(val_labels))\n",
        "  )\n",
        "  return history\n",
        "history = train_model(simple_model(), epochs, batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9weV4eGc9tp4"
      },
      "source": [
        "# Explore the training progress\n",
        "Show the training progress, by plotting the training and validation accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "jSw5Dp3f-XCw",
        "outputId": "f7961e5a-c1e7-4e9b-c545-3c258f7550b4",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_history(history:keras.callbacks.History, epochs:int):\n",
        "    epochrange = range(1, epochs + 1)\n",
        "    train_acc = history.history['categorical_accuracy']\n",
        "    val_acc = history.history['val_categorical_accuracy']\n",
        "\n",
        "    train_loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    plt.plot(epochrange, train_acc, 'bo', label='Training acc')\n",
        "    plt.plot(epochrange, val_acc, 'b', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy (modell 1)')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(epochrange, train_loss, 'bo', label='Training loss')\n",
        "    plt.plot(epochrange, val_loss, 'b', label='Validation loss')\n",
        "    plt.title('Training and validation loss (modell 1)')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "plot_history(history, epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn2kPMlsJxpW"
      },
      "source": [
        "Notera hur träningsnoggrannheten konstant går uppåt (och träningsförlusten nedåt). Medan valideringsförlusten bottnar ut någonstans mellan 5-10 epochs för att sedan långsamt går uppåt. Detta tyder på en svag överträning, om förlusten hade fortsatt nedåt tillsammans med träningsförlusten hade modellen fortfarande varit undertränad. Men överlag kan vi misstänka att modellens kapacitet vid 15 epochs är det bästa som denna modell kan åstadkomma."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6V9rOkX-bRa"
      },
      "source": [
        "# Evaluate the model on the test data.\n",
        "This first model get something around 89.5 % accuracy, not bad, but we can improve on this!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrwPwEQn-dVX",
        "outputId": "541479a3-ca5a-4040-c3be-208185d8ab79",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3863 - categorical_accuracy: 0.8958\n",
            "Test accuracy: 0.896\n"
          ]
        }
      ],
      "source": [
        "def eval(model:Model, data:str=\"test\"):\n",
        "    images, labels = str2data[data]\n",
        "    # Evaluate the model.\n",
        "    test_loss, test_acc = model.evaluate(images,to_categorical(labels))\n",
        "    print('Test accuracy: %.3f' % test_acc)\n",
        "    return test_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oR2HHYg2AoMK"
      },
      "source": [
        "# Övning Del 1a\n",
        "## Frågor att besvara:\n",
        "* Hur många parametrar har din modell?\n",
        "* Vilken testnoggrannhet får du? (Då modellen är slumpmässing initierad kan du få ett värde som skiljer sig lite grann.)\n",
        "* Om du tittar på träningsförloppet, har modellen tränat färdigt eller är den undertränad eller kanske övertränad, vad i träningskurvorna kan avgöra det?\n",
        "* Hur många epochs skulle ha varit lämpligt att använda?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kyZXtIvBtQz"
      },
      "source": [
        "# Del 1b - Fortsatta experiment:\n",
        "Det finns nu många saker du kan utforska men vi vill att du nu undersöker lite olika modeller. Undersök om du får en förbättring av testnoggrannhet ifall du gör modellen mer kraftfull (fler noder och/eller fler lager). Ha hela tiden ett öga på ifall modellen börjar överträna (att valideringsförlusten börjar gå uppåt igen). Notera att man gärna har med MaxPooling2D-lager mellan varje eller varannat faltningslager, då det hjälper med att hålla ner antalet parametrar vilket även leder till snabbare och ofta bättre träningsresultat (ger tex en viss extra translations och skalinvarians). Detta är speciellt viktigt om man har stora inbilder, men kan nog ge bra effekt även på våra minimala bilder.\n",
        "\n",
        "Målet är att få modellen att bli komplex nog att väl kunna representera data. En viss överträning är OK, vi ska ju sedan åtgärda det med regularisering.\n",
        "* Hur många faltningslager verkar rimligt att använda (håll dig under 4-5, det kan vara bättre att lägga till kärnor istället.\n",
        "* Hur många kärnor/noder verkar vettigt att använda?\n",
        "* Pröva även att använda ex 5x5 kärna för det första eller kanske något lager till, blir det bättre då? \n",
        "* Om en modell övertränar, gör ett experiment där du istället för att köra alla dina epochs slutar där verifieringsfelet börjar gå uppåt igen. Vad blir skillnaden i testnoggrannhet?\n",
        "\n",
        "Du behöver inte ha med kod för alla experiment, om du inte vill, men vi vill åtminstone se koden, träningsförloppet, och testnoggrannheten för din bästa modell.\n",
        "\n",
        "För minst en av dessa parameterinställningar ska du nå mer än 90% rätt på testdata för Fashion-MNIST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpSLuBimWmJk",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Kod för din bästa modell och dess träning och utvärdering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MMttcupPmiq"
      },
      "source": [
        "## Analys\n",
        "Dokumentera dina experiment, med modellkonfiguration, testnoggrannhet, och vid vilken epoch modellen börjar överträna.\n",
        "* Gör en sammanfattande analys av dina experiment hittills."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIR5LYQi6vDe"
      },
      "source": [
        "# Övning Del 2a - avbruten träning\n",
        "Utgå ifrån din bästa modell som du fått fram i del 1 och för den implementera avbruten träning (eng. early stopping) som ett sätt att förhindra överträning. [See Geron s. 141]\n",
        "\n",
        "Du behöver definiera en \"callback\" som sedan includeras i anropet till model.fit: *es=tf.keras.callbacks.EarlyStopping('val_loss', patience=3, restore_best_weights = True)*\n",
        "\n",
        "*model.fit(\n",
        "  train_images, to_categorical(train_labels),\n",
        "  epochs=epochs,\n",
        "  batch_size=batch_size,\n",
        "  **callbacks=[es]**,\n",
        "  validation_data=(val_images, to_categorical(val_labels))\n",
        ")*\n",
        "\n",
        "Viktigt är att notera restore_best_weights=True ifall man använder patience>0, för annars så har man en övertränad modell efter träningen.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eilf6C_E7Mcd",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Kod där du inför avbruten träning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaZR15OEJQKs"
      },
      "source": [
        "## Analys\n",
        "Vid vilken Epoch stannar nu träningen? Ändras nu modellens testnoggrannhet då den inte övertränar?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoYoC9KYTLtT"
      },
      "source": [
        "# Övning Del 2b Andra former av regularisering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0PXMFPccvP8"
      },
      "source": [
        "Utgå ifrån din bästa modell som du fått fram i del 1 men använd avbruten träning. Nu ska du skapa en modell som använder regularisering, tex. drop-out eller batchnormalisering. Analysera och jämför dessa modeller (med och utan regularisering) genom att notera deras testnoggrannhet och plotta tränings- och valideringsnoggrannheten (eng. accuracy) respektive förlust (eng. loss), och notera ifall en förbättring kan iakttas med regularisering. Hur många Epoch använder du för träningen? [See Geron s 338, s. 365]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xx3Il_R3TAjl",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Kod där du inför regularisering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ctk9BAgVIUCD"
      },
      "source": [
        "## Analys\n",
        "Analysera och jämför dina modeller (med och utan regularisering) genom att notera deras testnoggrannhet och plotta tränings- och valideringsnoggrannheten (eng. accuracy) respektive förlust (eng. loss), och notera ifall en förbättring kan iakttas med regularisering. Hur många Epoch använder du för träningen? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ominqognCKQ0"
      },
      "source": [
        "# Övriga Hyperparametrar\n",
        "Det finns ett antal andra viktiga parametrar som man kan behöva justera. Men flera av dem hänger ihop, så man behöver jobba med olika modeller och data för att få en bra känsla för dem. [See Geron s. 325.., s. 351.. ]\n",
        "* Batch size / batch storlek -- Ett större värde här kan ge GPUn mer parallellism att arbeta med, dvs snabbare, men ett för stort värde kan ge minnesproblem i GPUn och dessutom göra inlärningen långsammare (man kan dock även ha större LR i så fall.\n",
        "* Optimizer / optimerare -- En vanlig och bra optimerade är Adam (den är dessutom ganska okänslig för vilken inlärningstakt som den startar med, vilket gör att skönsvärdet fugerar bra). Medan sgd är en mer \"ursprunglig\" optimerare.\n",
        "* Learning rate / inlärningstakt (LR) -- Viktig parameter för hur snabbt modellen tränar, men för stort färde kan ge instabil träning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-7dDWzwGH9c"
      },
      "source": [
        "# Övning Del 2c\n",
        "Byt ut optimeraren från adam till sgd (med regularisering och avbruten träning). Jämför träningsförfarandet mellan de två optimerarna (skillnad i testnoggrannhet, vilken epoch stannade träningen, etc.?). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MeBdyzAHiCX",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Din kod för en körning med sgd som optimerare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7QvZC8ONS95"
      },
      "source": [
        "# Del 3 Auto tune\n",
        "Here we test on of the hyperparameter optimizers called Keras Tuner. Documentation can be found here: https://keras-team.github.io/keras-tuner/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCL16yCINhVS",
        "outputId": "1444fbcb-2ab9-468d-b7b4-67f70d9c6c2b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keras Tuner version: 1.1.2\n"
          ]
        }
      ],
      "source": [
        "# Get Keras Tuner (if in colab)\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  !pip install keras_tuner -q\n",
        "\n",
        "import keras_tuner\n",
        "print('Keras Tuner version:', keras_tuner.__version__)\n",
        "\n",
        "# Get some tuner search functions\n",
        "from keras_tuner.tuners import BayesianOptimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVNB09pdRwo1"
      },
      "source": [
        "## Exempelmodell (du ska sedan göra en egen!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkN7ntftOVQi",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# This is a straight forward CNN model to decently solve Fashion MNIST\n",
        "# Note that we have no regularisation for this example!\n",
        "# It can at least achieve 92% accuracy for me, with the parameters found:\n",
        "# conv_1_filter =  96, conv_1_kernel =   5, \n",
        "# conv_2_filter =  48, conv_2_kernel =   5\n",
        "# dense_1_units =  128\n",
        "# learning_rate = 0.001\n",
        "# batch_size = 320\n",
        "\n",
        "def build_model_2Conv1Dense(hp):  \n",
        "  model = tf.keras.Sequential([\n",
        "    # First Convolutional Layer\n",
        "    tf.keras.layers.Conv2D(\n",
        "        filters=hp.Int('conv_1_filter', min_value=32, max_value=256, step=32),\n",
        "        kernel_size=hp.Choice('conv_1_kernel', values = [3,5]),\n",
        "        activation='relu',\n",
        "        padding='same',\n",
        "        input_shape=(28,28,1)\n",
        "    ),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    # Second Convolutional Layer\n",
        "    tf.keras.layers.Conv2D(\n",
        "        filters=hp.Int('conv_2_filter', min_value=32, max_value=256, step=32),\n",
        "        kernel_size=hp.Choice('conv_2_kernel', values = [3,5]),\n",
        "        activation='relu',\n",
        "        padding='same'\n",
        "    ),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)),\n",
        "\n",
        "    # A First Dense Layer\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(\n",
        "        units=hp.Int('dense_1_units', min_value=32, max_value=256, step=32),\n",
        "        activation='relu'\n",
        "    ),\n",
        "\n",
        "    # A Final Dense Layer\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "  \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evRPRGRkOmpm"
      },
      "source": [
        "# Övning 3: Kod för instrumentera din egen model att optimeras med Keras Tuner\n",
        "Utgå ifrån din bästa modell som du fått fram i del 2 och instrumentera den för att optimeras med Keras Tuner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Haf7S-sOzKs",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Kompletera denna kod med din modell\n",
        "def build_model_MyModel(hp):  \n",
        "  model = tf.keras.Sequential([\n",
        "    # First Convolutional Layer5'\n",
        "    ##### YOUR CODE HERE! #####\n",
        "\n",
        "    # A Final Dense Layer\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "  \n",
        "  ##### You can also try some other learning rates in the next line, or use another optimizer with other parameters\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGMc2PtqWeoY"
      },
      "source": [
        "# Do the actual search, based on a BayesianOptimization\n",
        "Widely-used tuning algorithms: RandomSearch, BayesianOptimization and Hyperband. Here we will use BayesianOptimization. \n",
        "\n",
        "But note that there is a parameter *num_initial_points* to BayesianOptimization which state the number of randomly generated samples as initial training data for Bayesian optimization. If left unspecified, a value of 3 times the dimensionality of the hyperparameter space is used. That is, we might only use random search if we have too few trails."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10H7acwkPOpB",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# To get more stable results we are repeating the runs two times for each parameter setup\n",
        "MAX_TRIALS = 20         # represents the number of hyperparameter combinations that will be tested by the tuner\n",
        "EXECUTION_PER_TRIAL = 2 # the number of models that should be built and fit for each trial for robustness purposes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mw62ioE_PQKZ",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# To have batch_size as a hyperparameter we need to define our own tuner\n",
        "# In this case, we are basing it on the BayesianOptimization tuner found in\n",
        "# https://keras-team.github.io/keras-tuner/documentation/tuners/#bayesianoptimization-class\n",
        "class MyTuner(keras_tuner.tuners.BayesianOptimization):\n",
        "  def run_trial(self, trial, *args, **kwargs):\n",
        "    # You can add additional HyperParameters for preprocessing and custom training loops\n",
        "    # via overriding `run_trial`\n",
        "    kwargs['batch_size'] = trial.hyperparameters.Int('batch_size', 32, 512, step=32, default=256)\n",
        "    return super(MyTuner, self).run_trial(trial, *args, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMC8hgl3PZpI",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Bayesian search which also searches for batch_size\n",
        "tuner = MyTuner(\n",
        "    build_model_2Conv1Dense, ##### Laboration: Change this to 'build_model_MyModel' #####\n",
        "    max_trials=MAX_TRIALS,\n",
        "    objective='val_accuracy',\n",
        "    executions_per_trial=EXECUTION_PER_TRIAL,\n",
        "    directory='output',\n",
        "    overwrite=True,\n",
        "    num_initial_points=10, # Start with 10 random points and then do more structured search\n",
        "    project_name='FashionMNIST'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AqPBQEPfCw1"
      },
      "source": [
        "# Help it takes so much time!\n",
        "Yes, doing a parameter search takes time! Using a K80 this search takes 1h24 (while a RTX 3090 takes 10 minutes), and if your model is more complicated it can take even more time. To handle this you could try setting EXECUTION_PER_TRIAL=1, even if the search becomes more instable. You can also try to run in phases, do a first run with EXECUTION_PER_TRIAL=1 and even noepochauto = 4 or 5, to get a feeling for good parameter limits and starting points (setting things like \"default=128\" in the hp.Int() call) for your variables, and maybe even lock some variables (like LR?). And then do a more focused search where you maybe try EXECUTION_PER_TRIAL=2, noepochauto = 6 or 7 for a smaller number of MAX_TRIALS.\n",
        "\n",
        "If you do such multiphase process, please document it well!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEDRhLr8PdfO",
        "outputId": "a7adf6ca-5f6a-4990-c924-62d103092bad",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 20 Complete [00h 00m 25s]\n",
            "val_accuracy: 0.8767916858196259\n",
            "\n",
            "Best val_accuracy So Far: 0.9229583144187927\n",
            "Total elapsed time: 00h 14m 24s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ],
      "source": [
        "# Do the hyperparameter search\n",
        "# I set the no of epochs to 6 to speed up the search in this excersise, better would have been 10\n",
        "noepochauto = 6   ## Max number of epochs per trail (but we have early stopping so this max is probably not reached)\n",
        "es = tf.keras.callbacks.EarlyStopping('val_loss', patience=2, restore_best_weights = True)\n",
        "# Note we do not need to_catagorical as we use loss='sparse_categorical_crossentropy'\n",
        "tuner.search(train_images, train_labels, \n",
        "             epochs=noepochauto, \n",
        "             validation_data=(val_images, val_labels), \n",
        "             callbacks=[es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-VT_1v8PsjH",
        "outputId": "47ee2ccd-9e82-431e-e1e2-e65a91458d14",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       conv_1_filter = 224\n",
            "       conv_1_kernel =   5\n",
            "       conv_2_filter = 160\n",
            "       conv_2_kernel =   5\n",
            "       dense_1_units = 128\n",
            "       learning_rate = 0.001\n",
            "          batch_size = 384\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 256)       2560      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 28, 28, 256)      1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 256)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 50176)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 96)                4816992   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                970       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,411,626\n",
            "Trainable params: 5,411,114\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Get the best model so far\n",
        "model = tuner.get_best_models(num_models=1)[0]\n",
        "# Dump the best hyperparameters found\n",
        "vals = tuner.get_best_hyperparameters(num_trials=5)[4].values\n",
        "for keys,values in vals.items():\n",
        "    print('%20s = %3.4g' %(keys,values))\n",
        "    \n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qoom8_ADRJ87",
        "outputId": "1a582890-7fb0-4ab7-8d57-9580f153e7ea",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2340 - accuracy: 0.9221\n",
            "Test accuracy: 0.922\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model.\n",
        "test_loss, test_acc = model.evaluate(test_images,test_labels)\n",
        "print('Test accuracy: %.3f' % test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxuExn6aP3RB"
      },
      "source": [
        "## Code to explore the n-best models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V98UosuJQB83",
        "outputId": "f4d52db1-99ba-46fc-8082-140707d91008",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy   conv_1_filter   conv_1_kernel   conv_2_filter   conv_2_kernel   dense_1_units   learning_rate      batch_size \n",
            "\n",
            "          0.922             256               3             256               3              96           0.001             320 \n",
            "          0.913             160               3             256               3             256           0.001              32 \n",
            "          0.909             160               3             160               5              64           0.001             128 \n",
            "          0.907              32               5              32               5             256           0.001              32 \n",
            "          0.912             224               5             160               5             128           0.001             384 \n"
          ]
        }
      ],
      "source": [
        "# Let us dump the n-best\n",
        "\n",
        "if True:\n",
        "  explorenbest = 5\n",
        "\n",
        "  # Suppress warnings about optimizer state not being restored by tf.keras.\n",
        "  tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "  # Print a heading\n",
        "  vals = tuner.get_best_hyperparameters(num_trials=explorenbest)[0].values\n",
        "  print('Test accuracy ', end = '')\n",
        "  for keys,values in vals.items():\n",
        "      print('%15s ' %(keys), end = '')\n",
        "  print('\\n')\n",
        "\n",
        "  # Now print each trail on a seperate row from best to worst\n",
        "  for ix in range(0,explorenbest): \n",
        "    # evaluate this trail\n",
        "    model = tuner.get_best_models(num_models=explorenbest)[ix]\n",
        "    test_loss, test_acc = model.evaluate(test_images,test_labels, verbose=0)\n",
        "    print('%15.3f ' % test_acc , end = '')\n",
        "    # get this trail's hyperparameters\n",
        "    vals = tuner.get_best_hyperparameters(num_trials=explorenbest)[ix].values\n",
        "    for keys,values in vals.items():\n",
        "      print('%15.4g ' %(values), end = '')\n",
        "    # end this line and start the trail\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRG79o5edPAi"
      },
      "source": [
        "Notice that the model with the best validation accuracy not necessarily gives the best test accuracy! But we have to live with this as this is the best we can do with the data set aside for training and validation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix2PgTMaNPaT"
      },
      "source": [
        "# With our found hyperparameters, continue training\n",
        "(We do this especially as we only done 6 epochs during search.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74oCuObpNkPe",
        "outputId": "011767a0-a1ef-47d5-b8c4-5f701fde44fc",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "150/150 [==============================] - 5s 33ms/step - loss: 0.1083 - accuracy: 0.9617 - val_loss: 0.2441 - val_accuracy: 0.9157\n",
            "Epoch 2/30\n",
            "150/150 [==============================] - 5s 33ms/step - loss: 0.0818 - accuracy: 0.9707 - val_loss: 0.2697 - val_accuracy: 0.9184\n",
            "Epoch 3/30\n",
            "149/150 [============================>.] - ETA: 0s - loss: 0.0662 - accuracy: 0.9762Restoring model weights from the end of the best epoch: 1.\n",
            "150/150 [==============================] - 5s 33ms/step - loss: 0.0662 - accuracy: 0.9762 - val_loss: 0.2746 - val_accuracy: 0.9196\n",
            "Epoch 3: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Fine-tune the model using the best parameters found as we might not be fully trained\n",
        "model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "epochs = 30      ## (max) number of epoch to run\n",
        "opt_batch_size = tuner.get_best_hyperparameters()[0]['batch_size']\n",
        "\n",
        "# Set callback functions to early stop training\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=2, restore_best_weights = True)]\n",
        "\n",
        "# Continue to train the model. (note that we are continuing from the training done during tuning)\n",
        "history = model.fit(\n",
        "  train_images, train_labels,\n",
        "  epochs=epochs,\n",
        "  batch_size=opt_batch_size,\n",
        "  verbose = 1,\n",
        "  validation_data=(val_images, val_labels),\n",
        "  # initial_epoch=noepochauto, ## how to get this number???? from... \"(root).optimizer.iter\" maybe\n",
        "  callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAsos-f4Nye8",
        "outputId": "974b09da-364e-4755-a4a8-cb4b3d792c63",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2534 - accuracy: 0.9160\n",
            "Test accuracy: 0.916\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model.\n",
        "test_loss, test_acc = model.evaluate(test_images,test_labels)\n",
        "print('Test accuracy: %.3f' % test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WketomR6iVWk",
        "outputId": "5499e976-cf02-4aa2-8d69-774b83fd0053",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 256)       2560      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 28, 28, 256)      1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 256)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 50176)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 96)                4816992   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                970       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,411,626\n",
            "Trainable params: 5,411,114\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# See what we got and how many parameters are used\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQKU8ZEXQZDV"
      },
      "source": [
        "#Analys\n",
        "Gör en komplett analys av de optimerade modellerna du fått fram mha Keras Tuner. Några frågor man kan ställa sig:\n",
        "* Hur jämför sig dessa värden, mha en Bayesiansk sökning, från de värden då fått fram i del 1 och del 2? \n",
        "* Vilka prestanda fick du för de olika fallen? \n",
        "* Finns det parametrar som ligger vid ändvärdena av den använda sökrymden? (i så fall kanske du borde köra om med utökade gränser?)\n",
        "* Vilka hyperparametrar verkade vara mest betydelsefulla? \n",
        "* Kan man se någon trend bland parametrarna (tex antalet faltningskärnor i tidiga respektive sena lager, etc)? \n",
        "* Varför utför man samma experiment flera gångar \"EXECUTION_PER_TRIAL = 2\", dvs varför blir det inte samma resultat varje gång?\n",
        "* Annat som du iaktagit?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V67KzZlmckBw"
      },
      "source": [
        "# Uppgifter för väl godkänt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDD_rMGXcsyX"
      },
      "source": [
        "Utökning av Del2: Utforska de testfall som missklassificerades för en av dina toppmodeller, vilka typer av plagg verkar vara de som oftast blir fel på, om du tittar på dessa fel förstår du varför nätet har problem med dem?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1K5x5iL39A22",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Din kod som utforskar de testfall som missklassificerades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81rFfKrm9HaC"
      },
      "source": [
        "Utökning av Del3: Implementera en undersökning där du även varierar antal lager i din modell, du kan ändra både faltningslager och kompakta lager (eng. dense layers) för att se ifall en ännu bättre modell kan hittas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lQPNnmYdNBR"
      },
      "source": [
        "Tips: Det är nog bäst att använda en inkrementell/funktionell definition av modellen (där lager läggs till med \"model.add(...)\" för då blir det lättare att göra en for-slinga runt koden som lägger till ett visst antal lager. Jmf https://keras.io/guides/sequential_model/ \n",
        "\n",
        "\n",
        "```\n",
        "    filter1=hp.Int('conv_pre_filter', min_value=32, max_value=160, step=32, default=64)\n",
        "    kernel1=hp.Choice('conv_pre_kernel', values = [3,5], default=3)\n",
        "    model = Sequential()\n",
        "    # Add a first convolution layer (with input size)\n",
        "    model.add(Conv2D(filters=filter1, kernel_size=kernel1, padding='same', activation='relu', input_shape=train_images[0].shape))\n",
        "    # More fixed layers?\n",
        "    model.add(....more layer definitions....) \n",
        "    # Add a varying number of layers\n",
        "    no_layers = hp.Int('num_layers', 0, 3)\n",
        "    for i in range(no_layers):\n",
        "          model.add(Conv2D(filters=hp.Int(f'conv_{i+1}_units', ...parameters...), \n",
        "                          kernel_size=hp.Choice(f'conv_{i+1}_kernel', ...parameters....),\n",
        "                          activation='relu'\n",
        "                          )\n",
        "                    )\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JR43zXtw9VSx",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Din kod för en keras tuner modell som har antalet lager som en hyperparameter \n",
        "# och där du söker efter optimerade hyperparametrar för denna modell."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "7MMttcupPmiq"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
